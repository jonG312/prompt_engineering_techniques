{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jonG312/prompt_engineering_techniques/blob/main/VII_chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XHAwq7rpfGnd"
      },
      "source": [
        "# The Chat Format\n",
        "exploring how utilize the chat format to have extended conversations with chatbots personalized or specialized for specific tasks or behaviors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Hcd_SVdhgaRj"
      },
      "outputs": [],
      "source": [
        "# Basic congfig\n",
        "# Install basic package and set key\n",
        "!pip install openai\n",
        "!pip install python-dotenv"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nQf1VurXgaRl"
      },
      "outputs": [],
      "source": [
        "import openai\n",
        "import os\n",
        "\n",
        "openai.api_key  = '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'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KmGvWRCRgaRl"
      },
      "outputs": [],
      "source": [
        "def get_completion(prompt, model=\"gpt-3.5-turbo\"):\n",
        "    messages = [{\"role\": \"user\", \"content\": prompt}]\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=0, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "    return response.choices[0].message[\"content\"]\n",
        "\n",
        "def get_completion_from_messages(messages, model=\"gpt-3.5-turbo\", temperature=0):\n",
        "    response = openai.ChatCompletion.create(\n",
        "        model=model,\n",
        "        messages=messages,\n",
        "        temperature=temperature, # this is the degree of randomness of the model's output\n",
        "    )\n",
        "#     print(str(response.choices[0].message))\n",
        "    return response.choices[0].message[\"content\"]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Bv3AWuHbgaRl"
      },
      "outputs": [],
      "source": [
        "messages =  [\n",
        "{'role':'system', 'content':'You are an assistant that speaks like Shakespeare.'},\n",
        "{'role':'user', 'content':'tell me a joke'},\n",
        "{'role':'assistant', 'content':'Why did the chicken cross the road'},\n",
        "{'role':'user', 'content':'I don\\'t know'}  ]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8NCEv1E_gaRm",
        "outputId": "ccfb70a9-82fd-4a80-9330-6f5dd6a8fecc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "To get to the other side! Ah, tis but a classic jest!\n"
          ]
        }
      ],
      "source": [
        "response = get_completion_from_messages(messages, temperature=1)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8TgGDrG-gaRm",
        "outputId": "f72736ab-2efc-4888-c304-799d74c11581"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Hi Isa, it's nice to meet you! How can I assist you today?\n"
          ]
        }
      ],
      "source": [
        "messages =  [\n",
        "{'role':'system', 'content':'You are friendly chatbot.'},\n",
        "{'role':'user', 'content':'Hi, my name is Isa'}  ]\n",
        "response = get_completion_from_messages(messages, temperature=1)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "odXaQ4GjgaRn",
        "outputId": "4985e2f1-6fa3-4cf0-aa24-72fb908696d4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "I'm sorry, I don't have access to that information. Since I'm just a computer program, I don't have the ability to retain information from previous conversations. However, you are welcome to tell me your name and anything else you'd like to share!\n"
          ]
        }
      ],
      "source": [
        "messages =  [\n",
        "{'role':'system', 'content':'You are friendly chatbot.'},\n",
        "{'role':'user', 'content':'Yes,  can you remind me, What is my name?'}  ]\n",
        "response = get_completion_from_messages(messages, temperature=1)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wV54IT7RgaRn"
      },
      "outputs": [],
      "source": [
        "messages =  [\n",
        "{'role':'system', 'content':'You are friendly chatbot.'},\n",
        "{'role':'user', 'content':'Hi, my name is Isa'},\n",
        "{'role':'assistant', 'content': \"Hi Isa! It's nice to meet you. \\\n",
        "Is there anything I can help you with today?\"},\n",
        "{'role':'user', 'content':'Yes, you can remind me, What is my name?'}  ]\n",
        "response = get_completion_from_messages(messages, temperature=1)\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LPQ4yqG7gaRn"
      },
      "source": [
        "# OrderBot\n",
        "We can automate the collection of user prompts and assistant responses to build a  OrderBot. The OrderBot will take orders at a pizza restaurant."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "q2ncs_-XgaRo"
      },
      "outputs": [],
      "source": [
        "!pip install panel jupyter_bokeh"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oCsYnBmtgaRo"
      },
      "outputs": [],
      "source": [
        "def collect_messages(_):\n",
        "    prompt = inp.value_input\n",
        "    inp.value = ''\n",
        "    context.append({'role':'user', 'content':f\"{prompt}\"})\n",
        "    response = get_completion_from_messages(context)\n",
        "    context.append({'role':'assistant', 'content':f\"{response}\"})\n",
        "    panels.append(\n",
        "        pn.Row('User:', pn.pane.Markdown(prompt, width=600)))\n",
        "    panels.append(\n",
        "        pn.Row('Assistant:', pn.pane.Markdown(response, width=600, style={'background-color': '#F6F6F6'})))\n",
        "\n",
        "    return pn.Column(*panels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BUwCxATogaRo"
      },
      "outputs": [],
      "source": [
        "import panel as pn  # GUI\n",
        "pn.extension()\n",
        "\n",
        "panels = [] # collect display\n",
        "\n",
        "context = [ {'role':'system', 'content':\"\"\"\n",
        "You are OrderBot, an automated service to collect orders for a pizza restaurant. \\\n",
        "You first greet the customer, then collects the order, \\\n",
        "and then asks if it's a pickup or delivery. \\\n",
        "You wait to collect the entire order, then summarize it and check for a final \\\n",
        "time if the customer wants to add anything else. \\\n",
        "If it's a delivery, you ask for an address. \\\n",
        "Finally you collect the payment.\\\n",
        "Make sure to clarify all options, extras and sizes to uniquely \\\n",
        "identify the item from the menu.\\\n",
        "You respond in a short, very conversational friendly style. \\\n",
        "The menu includes \\\n",
        "pepperoni pizza  12.95, 10.00, 7.00 \\\n",
        "cheese pizza   10.95, 9.25, 6.50 \\\n",
        "eggplant pizza   11.95, 9.75, 6.75 \\\n",
        "fries 4.50, 3.50 \\\n",
        "greek salad 7.25 \\\n",
        "Toppings: \\\n",
        "extra cheese 2.00, \\\n",
        "mushrooms 1.50 \\\n",
        "sausage 3.00 \\\n",
        "canadian bacon 3.50 \\\n",
        "AI sauce 1.50 \\\n",
        "peppers 1.00 \\\n",
        "Drinks: \\\n",
        "coke 3.00, 2.00, 1.00 \\\n",
        "sprite 3.00, 2.00, 1.00 \\\n",
        "bottled water 5.00 \\\n",
        "\"\"\"} ]  # accumulate messages\n",
        "\n",
        "\n",
        "inp = pn.widgets.TextInput(value=\"Hi\", placeholder='Enter text hereâ€¦')\n",
        "button_conversation = pn.widgets.Button(name=\"Chat!\")\n",
        "\n",
        "interactive_conversation = pn.bind(collect_messages, button_conversation)\n",
        "\n",
        "dashboard = pn.Column(\n",
        "    inp,\n",
        "    pn.Row(button_conversation),\n",
        "    pn.panel(interactive_conversation, loading_indicator=True, height=300),\n",
        ")\n",
        "\n",
        "dashboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3rUybkangaRp"
      },
      "outputs": [],
      "source": [
        "messages =  context.copy()\n",
        "messages.append(\n",
        "{'role':'system', 'content':'create a json summary of the previous food order. Itemize the price for each item\\\n",
        " The fields should be 1) pizza, include size 2) list of toppings 3) list of drinks, include size   4) list of sides include size  5)total price '},\n",
        ")\n",
        " #The fields should be 1) pizza, price 2) list of toppings 3) list of drinks, include size include price  4) list of sides include size include price, 5)total price '},\n",
        "\n",
        "response = get_completion_from_messages(messages, temperature=0)\n",
        "print(response)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "gpt_index",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    },
    "orig_nbformat": 4
  },
  "nbformat": 4,
  "nbformat_minor": 0
}